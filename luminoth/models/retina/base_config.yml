model:
  type: retina
  share_weights: True
  anchors:
    # Base size to use for anchors.
    # This is the size in level-'pixels'.
    base_size: 8
    # Aspect ratios used for generating anchors (paper values)
    ratios: [0.5, 1., 2.]
    # Scales of the anchors (paper values)
    scales: [0.6, 1.0, 1.3]
    # How many pixels outside the level we will allow the anchor to be.
    offset: 0

  network:
    num_classes: 20
  base_network:
    # Which type of pretrained network to use
    architecture: resnet_v1_101
    # Should we train the pretrained network
    trainable: True
    # From which file to load the weights
    weights:
    # Should we download weights if not available
    download: True
    arg_scope:
      # The l2 regularization coefficient.
      weight_decay: 0.0005
    dropout_keep_prob: 1.0
  fpn:
    num_channels: 256 # paper value
    endpoints:
      - 'block4/unit_3/bottleneck_v1/conv3'
      - 'block3/unit_23/bottleneck_v1/conv1'
      - 'block2/unit_4/bottleneck_v1/conv1'

  loss:
    gamma: 2.0  # paper value
    # Sigma value for L1 loss.
    l1_sigma: 3.0
    # Weight for the class loss.
    class_weight: 1.
    # Weight for the regression loss.
    reg_weight: 10.
    # The weight of the loss for background will be divided by this number.
    # Due to our use of the focal loss, high values here are overkill.
    background_weight_divider: 16.
    # Whether or not to sum all the loss values. If it's set to False, we use
    # reduce_mean.
    reduce_sum: True

  # Config for BBox delta prediction subnets.
  box_subnet:
    l2_regularization_scale: 0.0005
    dropout_keep_prob: 0.8
    # Config for the hidden layers of the net.
    hidden:
      depth: 4
      channels: 256
      kernel_shape: [3, 3]
      activation: relu
    # Config for the final layer of the net.
    final:
      kernel_shape: [3, 3]
      # activations here can severely limit the capacity of the network of
      # predicting deltas for anchors.
      activation: ""

  # Config for classification subnet(s).
  class_subnet:
    l2_regularization_scale: 0.0005
    dropout_keep_prob: 0.8
    # Config for the hidden layers of the net.
    hidden:
      # Number of layers.
      depth: 4
      # Number of output channels.
      channels: 256
      kernel_shape: [3, 3]
      activation: relu6
    # Config for the final layer of the net.
    final:
      init_bias:
        # These will be the initial scores (approx) of foregrounds and
        # background.
        foreground: -0.5
        background: 2.
      kernel_shape: [3, 3]
      activation: ""

  target:
    # Threshold with GT to be considered positive
    foreground_threshold: 0.5
    # High and low threshold with GT to be considered negative
    background_threshold_high: 0.4  # AMIP (Retina)
    background_threshold_low: 0.0

  proposals:
    # Maximum number of detections for each class
    class_max_detections: 100
    # NMS threshold used to remove "almost duplicate" of the same class
    class_nms_threshold: 0.3
    # Maximum total detections for an image (sorted by score)
    total_max_detections: 300
    # Minimum prob to be used as proposed object
    min_prob_threshold: 0.4
    # Number of proposals to decode before applying nms.
    pre_nms_top_n: 5000

dataset:
  type: tfrecord
  split: 'train'
  image_preprocessing:
    min_size: 300
    max_size: 900
  # Data augmentation techniques
  data_augmentation:
    - flip:
        left_right: True
        up_down: False
        prob: 0.5
    # If you resize to too small images, you may end up not having any anchors
    # that aren't partially outside the image.
    - resize:
        min_size: 300
        max_size: 900
        prob: 0.05
    - patch:
        min_height: 300
        min_width: 300
        prob: 0.1
    - distortion:
        brightness:
          max_delta: 0.1
        hue:
          max_delta: 0.05
        saturation:
          lower: 0.8
          upper: 1.2
        prob: 0.3

eval:
  # Image visualization mode, options = train, eval, debug, (empty). Default=(empty)
  image_vis: eval

train:
  debug: False
  tf_debug: False
  job_dir: jobs
  seed:
  num_epochs: 1000
  # TODO: make other batch_size-s work.
  batch_size: 1

  run_name:
  # Disables logging and saving checkpoints
  no_log: False
  # Displays debugging images with results every N steps. Debug mode must be
  # enabled
  display_every_steps:
  # Display debugging images every N seconds.
  display_every_secs: 300
  # Shuffle the dataset. It should only be disabled when trying to reproduce
  # some problem on some sample
  random_shuffle: True
  # Save Tensorboard timeline
  save_timeline: False
  # The frequency, in seconds, that a checkpoint is saved.
  save_checkpoint_secs: 600
  # The frequency, in number of global steps, that the summaries are written to disk
  save_summaries_steps:
  # The frequency, in secs, that the summaries are written to disk.
  # If both save_summaries_steps and save_summaries_secs are set to empty, then the
  # default summary saver isn't used
  save_summaries_secs: 30
  # Run TensorFlow using full_trace mode for memory and running time logging
  # Debug mode must be enabled.
  full_trace: False
  # Clip gradients by norm, making sure the maximum value is 10.
  clip_by_norm: False
  # Learning rate config.
  learning_rate:
    # Because we're using kwargs, we want the learning_rate dict to be replaced
    # as a whole.
    _replace: True
    # Learning rate decay method ((empty), "none", piecewise_constant, exponential_decay, polynomial_decay)
    # You can define different decay methods using `decay_method` and defining all the necessary arguments.
    decay_method: piecewise_constant
    values: [0.001, 0.0001, 0.00001]
    boundaries:
      - 40000
      - 60000

  # Optimizer config
  optimizer:
    # Because we're using kwargs, we want the optimizer dict to be replaced
    # as a whole.
    _replace: True
    # Type of optimizer to use (momentum, adam, gradient_descent, rmsprop)
    type: momentum
    # any options are passed directly to the optimizer as kwarg.
    momentum: 0.9
